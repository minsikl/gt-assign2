{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e95d094-a0ce-467a-9d50-26308034dd30",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Weight Optimization - SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e10c2746-8b52-4d0c-8cfa-d18e70788020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# 0. Import Packages\n",
    "#\n",
    "\n",
    "# han: check if random seed is necessary\n",
    "RANDOM_SEED = 7641\n",
    "\n",
    "# Math tools for ML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "from numpy import arange\n",
    "\n",
    "# Randomized Optimization \n",
    "import mlrose_hiive\n",
    "\n",
    "# Progress bar\n",
    "#from tqdm import tqdm\n",
    "\n",
    "# Graph visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.optim as optim\n",
    "#import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Model \n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Tree\n",
    "from sklearn.ensemble import AdaBoostClassifier # Boosted Decision Tree\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "\n",
    "#from sklearn import tree\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2004113-bf7e-4807-a4cd-db9eb0eae320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_raw dimension:  (2139, 23)\n",
      "y_raw dimension:  (2139,)\n"
     ]
    }
   ],
   "source": [
    "# Load UCI AIDS crinical dataset - https://archive.ics.uci.edu/dataset/890/aids+clinical+trials+group+study+175\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "aids_clinical_trials_group_study_175 = fetch_ucirepo(id=890) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = aids_clinical_trials_group_study_175.data.features \n",
    "y = aids_clinical_trials_group_study_175.data.targets \n",
    "y=y.cid\n",
    "\n",
    "X_raw = X\n",
    "y_raw = y\n",
    "\n",
    "print(\"x_raw dimension: \", X_raw.shape)\n",
    "print(\"y_raw dimension: \", y_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3448933-9f2a-49d4-ae46-1b44578a874a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# 1.1 Tensor Data Type (Pytorch)\n",
    "#\n",
    "\n",
    "#X_raw = torch.tensor(X_raw, dtype=torch.float32)\n",
    "#y_raw = torch.tensor(y_raw, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2bdcf5-68b5-454c-8044-e88a48a181f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1711, 2)\n",
      "(428, 2)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 1.2 Split train and test sets\n",
    "#\n",
    "\n",
    "# data type change \n",
    "#y_raw = y_raw.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, stratify=y_raw, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(y_train.values.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.values.reshape(-1, 1)).todense()\n",
    "\n",
    "# print # of X_train\n",
    "print(y_train_hot.shape)\n",
    "print(y_test_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c699f3b-2c11-425f-a69e-c3b54725f67a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10 1 0.7393364363289174 0.7336448598130841 0.10776264000014635\n",
      "1 10 10 0.7510238180485226 0.7570093457943925 0.08480968000003486\n",
      "1 10 100 0.7364005251223296 0.7570093457943925 0.08237170100073854\n",
      "1 10 200 0.7364005251223296 0.7570093457943925 0.08212224700037041\n",
      "1 100 1 0.750413448587455 0.7570093457943925 0.7513525720005418\n",
      "1 100 10 0.7492438579441801 0.7336448598130841 0.7224733590010146\n",
      "1 100 100 0.7469132013707739 0.7336448598130841 0.7480514079998102\n",
      "1 100 200 0.7463352258196511 0.7336448598130841 0.7283265509995545\n",
      "1 1000 1 0.741687552213868 0.7593457943925234 4.490083221999157\n",
      "1 1000 10 0.7562818611153734 0.7570093457943925 7.181836433999706\n",
      "1 1000 100 0.753354474621929 0.7570093457943925 7.3146886699996685\n",
      "1 1000 200 0.7562716314596014 0.7570093457943925 7.492371214000741\n",
      "10 10 1 0.7434351184082655 0.7336448598130841 0.08095185499951185\n",
      "10 10 10 0.7510238180485226 0.7570093457943925 0.08051207599964982\n",
      "10 10 100 0.7364005251223296 0.7570093457943925 0.07886442500057456\n",
      "10 10 200 0.7364005251223296 0.7570093457943925 0.07652356500148016\n",
      "10 100 1 0.750413448587455 0.7570093457943925 0.7529104740006005\n",
      "10 100 10 0.7492438579441801 0.7336448598130841 0.7496510580003815\n",
      "10 100 100 0.7469132013707739 0.7336448598130841 0.7611986840001919\n",
      "10 100 200 0.7463352258196511 0.7336448598130841 0.7590261490004195\n",
      "10 1000 1 0.7457811194653299 0.7570093457943925 7.418626848999338\n",
      "10 1000 10 0.7457589552111571 0.7383177570093458 7.480697955999858\n",
      "10 1000 100 0.7340647537210373 0.6892523364485982 7.507290322999324\n",
      "10 1000 200 0.7516000886570167 0.7570093457943925 7.734287671000857\n",
      "100 10 1 0.7404889775459056 0.7336448598130841 0.0795034589991701\n",
      "100 10 10 0.7510238180485226 0.7570093457943925 0.07539697800166323\n",
      "100 10 100 0.7364005251223296 0.7570093457943925 0.07959277299960377\n",
      "100 10 200 0.7364005251223296 0.7570093457943925 0.07866361599917582\n",
      "100 100 1 0.750413448587455 0.7570093457943925 0.7483375219999289\n",
      "100 100 10 0.7492438579441801 0.7336448598130841 0.7440646169998217\n",
      "100 100 100 0.7469132013707739 0.7336448598130841 0.7196112229994469\n",
      "100 100 200 0.7463352258196511 0.7336448598130841 0.709415209999861\n",
      "100 1000 1 0.7457811194653299 0.7570093457943925 7.430857737999759\n",
      "100 1000 10 0.7457589552111571 0.7383177570093458 7.56932459500058\n",
      "100 1000 100 0.7340647537210373 0.6892523364485982 7.649041173001024\n",
      "100 1000 200 0.7516000886570167 0.7570093457943925 7.917574943001455\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 2. Learning Curve\n",
    "#\n",
    "\n",
    "max_attempts = [ 1, 10, 100]\n",
    "max_iters = [10, 100, 1000]\n",
    "temperatures = [1, 10, 100, 200]\n",
    "\n",
    "\n",
    "results_column = [\"temperature\", \"max_iters\", \"accuracy_train\", \"accuracy_test\", \"train_time\"]\n",
    "results_list = []\n",
    "results_df = pd.DataFrame(columns=results_column)\n",
    "\n",
    "for max_attempt in max_attempts:\n",
    "    for max_iter in max_iters:\n",
    "        for t in temperatures: \n",
    "        \n",
    "            kfold = KFold(n_splits=5, shuffle=True)\n",
    "            cv_scores  = []\n",
    "                \n",
    "            start_time = time.perf_counter()\n",
    "            nn_model = mlrose_hiive.NeuralNetwork(hidden_nodes = [2], \n",
    "                                                      activation = 'relu' ,\n",
    "                                                      algorithm = 'simulated_annealing',\n",
    "                                                      is_classifier = True,\n",
    "                                                      early_stopping = True,\n",
    "                                                      random_state = RANDOM_SEED,\n",
    "                                                      max_attempts = max_attempt,\n",
    "                                                      max_iters = max_iter,\n",
    "                                                      schedule=mlrose_hiive.ArithDecay(init_temp=t))\n",
    "    \n",
    "            for train, validate in kfold.split(X_train_scaled, y_train_hot):\n",
    "                nn_model.fit(X_train_scaled[train], y_train_hot[train])\n",
    "                y_pred_hot = nn_model.predict(X_train_scaled[validate])\n",
    "                accuracy = mt.accuracy_score(np.asarray(y_pred_hot), np.asarray(y_train_hot[validate]))\n",
    "                cv_scores.append(accuracy)\n",
    "                \n",
    "            train_time = time.perf_counter() - start_time\n",
    "    \n",
    "            accuracy_train = np.mean(cv_scores)\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                y_pred_hot = nn_model.predict(X_test_scaled)\n",
    "            accuracy_test = mt.accuracy_score(np.asarray(y_test_hot), np.asarray(y_pred_hot))\n",
    "                \n",
    "            results_df.loc[len(results_df.index)] = [max_attempt, max_iter, t, accuracy_test, train_time]\n",
    "            print(max_attempt, max_iter, t, accuracy_train, accuracy_test, train_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
