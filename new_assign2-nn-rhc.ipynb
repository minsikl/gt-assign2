{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e95d094-a0ce-467a-9d50-26308034dd30",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Weight Optimization - RHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e10c2746-8b52-4d0c-8cfa-d18e70788020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# 0. Import Packages\n",
    "#\n",
    "\n",
    "# han: check if random seed is necessary\n",
    "RANDOM_SEED = 7641\n",
    "\n",
    "# Math tools for ML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "from numpy import arange\n",
    "\n",
    "# Randomized Optimization \n",
    "import mlrose_hiive\n",
    "\n",
    "# Progress bar\n",
    "#from tqdm import tqdm\n",
    "\n",
    "# Graph visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.optim as optim\n",
    "#import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Model \n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Tree\n",
    "from sklearn.ensemble import AdaBoostClassifier # Boosted Decision Tree\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "\n",
    "#from sklearn import tree\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2004113-bf7e-4807-a4cd-db9eb0eae320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_raw dimension:  (2139, 23)\n",
      "y_raw dimension:  (2139,)\n"
     ]
    }
   ],
   "source": [
    "# Load UCI AIDS crinical dataset - https://archive.ics.uci.edu/dataset/890/aids+clinical+trials+group+study+175\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "aids_clinical_trials_group_study_175 = fetch_ucirepo(id=890) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = aids_clinical_trials_group_study_175.data.features \n",
    "y = aids_clinical_trials_group_study_175.data.targets \n",
    "y=y.cid\n",
    "\n",
    "X_raw = X\n",
    "y_raw = y\n",
    "\n",
    "print(\"x_raw dimension: \", X_raw.shape)\n",
    "print(\"y_raw dimension: \", y_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3448933-9f2a-49d4-ae46-1b44578a874a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# 1.1 Tensor Data Type (Pytorch)\n",
    "#\n",
    "\n",
    "#X_raw = torch.tensor(X_raw, dtype=torch.float32)\n",
    "#y_raw = torch.tensor(y_raw, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2bdcf5-68b5-454c-8044-e88a48a181f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1711, 2)\n",
      "(428, 2)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 1.2 Split train and test sets\n",
    "#\n",
    "\n",
    "# data type change \n",
    "#y_raw = y_raw.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, stratify=y_raw, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(y_train.values.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.values.reshape(-1, 1)).todense()\n",
    "\n",
    "# print # of X_train\n",
    "print(y_train_hot.shape)\n",
    "print(y_test_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e96df18-7a56-411b-802a-0cae139db750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10 0 0.7469200211412886 0.7429906542056075 0.015476392999971722\n",
      "1 10 10 0.7294085554021107 0.7266355140186916 0.14985384800002066\n",
      "1 10 100 0.7440130939593883 0.7406542056074766 1.5427550819999851\n",
      "1 100 0 0.7469149063134026 0.7429906542056075 0.010777537999729248\n",
      "1 100 10 0.7294085554021107 0.7266355140186916 0.14035427099997833\n",
      "1 100 100 0.7440130939593883 0.7406542056074766 1.381783538000036\n",
      "1 1000 0 0.7469149063134026 0.7429906542056075 0.010540342000240344\n",
      "1 1000 10 0.7294085554021107 0.7266355140186916 0.13488021300008768\n",
      "1 1000 100 0.7440130939593883 0.7406542056074766 1.3497192700001506\n",
      "10 10 0 0.7445842497399963 0.7453271028037384 0.05319821500006583\n",
      "10 10 10 0.7387516410072801 0.7429906542056075 0.646781547000046\n",
      "10 10 100 0.7381549110872421 0.7336448598130841 6.303099796999959\n",
      "10 100 0 0.7411095766627452 0.7476635514018691 0.5453115380000781\n",
      "10 100 10 0.7609670434589876 0.7686915887850467 6.034232010999858\n",
      "10 100 100 0.7586295671150667 0.7710280373831776 56.82627205400013\n",
      "10 1000 0 0.7545735086014356 0.7383177570093458 1.1677196730001924\n",
      "10 1000 10 0.8217567728845925 0.8200934579439252 22.533839940000234\n",
      "10 1000 100 0.8199802226655073 0.8177570093457944 196.0067883390002\n",
      "100 10 0 0.7481049562682214 0.7453271028037384 0.0599930830003359\n",
      "100 10 10 0.7387516410072801 0.7429906542056075 0.7329918499999621\n",
      "100 10 100 0.7381549110872421 0.7336448598130841 7.186799117999726\n",
      "100 100 0 0.7422757574207628 0.7476635514018691 0.6362190519998876\n",
      "100 100 10 0.7609670434589877 0.7733644859813084 7.227744242999961\n",
      "100 100 100 0.7603754283668355 0.7757009345794392 62.81243094999991\n",
      "100 1000 0 0.8322575145346359 0.8294392523364486 4.885651923999831\n",
      "100 1000 10 0.8322779738461801 0.8271028037383178 54.383245116000126\n",
      "100 1000 100 0.8439619456805278 0.8294392523364486 559.5538162029998\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 2. Learning Curve\n",
    "#\n",
    "\n",
    "max_attempts = [ 1, 10, 100]\n",
    "max_iters = [10, 100, 1000]\n",
    "restarts = [0, 10, 100]\n",
    "\n",
    "results_column = [\"max_attempts\", \"max_iters\", \"restart\", \"accuracy_train\", \"accuracy_test\", \"train_time\"]\n",
    "results_list = []\n",
    "results_df = pd.DataFrame(columns=results_column)\n",
    "\n",
    "for max_attempt in max_attempts:\n",
    "    for max_iter in max_iters:\n",
    "        for restart in restarts: \n",
    "            \n",
    "            kfold = KFold(n_splits=5, shuffle=True)\n",
    "            cv_scores  = []\n",
    "            \n",
    "            start_time = time.perf_counter()\n",
    "            nn_model = mlrose_hiive.NeuralNetwork(hidden_nodes = [2], \n",
    "                                                  activation = 'relu' ,\n",
    "                                                  algorithm = 'random_hill_climb',\n",
    "                                                  is_classifier = True,\n",
    "                                                  early_stopping = True,\n",
    "                                                  random_state = RANDOM_SEED,\n",
    "                                                  max_attempts = max_attempt,\n",
    "                                                  max_iters = max_iter,\n",
    "                                                  restarts = restart)\n",
    "\n",
    "            for train, validate in kfold.split(X_train_scaled, y_train_hot):\n",
    "                nn_model.fit(X_train_scaled[train], y_train_hot[train])\n",
    "                y_pred_hot = nn_model.predict(X_train_scaled[validate])\n",
    "                accuracy = mt.accuracy_score(np.asarray(y_pred_hot), np.asarray(y_train_hot[validate]))\n",
    "                cv_scores.append(accuracy)\n",
    "            \n",
    "            train_time = time.perf_counter() - start_time\n",
    "\n",
    "            accuracy_train = np.mean(cv_scores)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                y_pred_hot = nn_model.predict(X_test_scaled)\n",
    "            accuracy_test = mt.accuracy_score(np.asarray(y_test_hot), np.asarray(y_pred_hot))\n",
    "            \n",
    "            results_df.loc[len(results_df.index)] = [max_attempt, max_iter, restart, accuracy_train, accuracy_test, train_time]\n",
    "            print(max_attempt, max_iter, restart, accuracy_train, accuracy_test, train_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
